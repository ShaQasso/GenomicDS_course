---
title: "Ex6"
author:
        - "Shaqed Carasso" 
        - "ID: 201281805"
date: "14/12/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
expFile=system.file("extdata",
                    "leukemiaExpressionSubset.rds",
                    package="compGenomRData")

mat=readRDS(expFile)
```

1. We want to observe the effect of data transformation in this exercise. Scale the expression matrix with the scale() function. In addition, try taking the logarithm of the data with the log2() function prior to scaling. Make box plots of the unscaled and scaled data sets using the boxplot() function. [Difficulty: Beginner/Intermediate]

```{r include=FALSE}
 # The traditional way of scaling variables is to subtract their mean, and divide by their standard deviation, this operation is also called “standardization”. If this is done on all genes, each gene will have the same effect on distance measures. In R, the standardization is done via the scale() function. Here we scale the gene expression values.

boxplot(mat)

scaledMat <- scale(mat)
boxplot(scaledMat)

logMat <- log2(mat)
boxplot(logMat)

scaledLogMat <- scale(logMat)
boxplot(scaledLogMat)
```


2. For the same problem above using the unscaled data and different data transformation strategies, use the ward.d distance in hierarchical clustering and plot multiple heatmaps. You can try to use the pheatmap library or any other library that can plot a heatmap with a dendrogram. Which data-scaling strategy provides more homogeneous clusters with respect to disease types? [Difficulty: Beginner/Intermediate]

```{r include=FALSE}
library(pheatmap)

# set the leukemia type annotation for each sample
annotation_col = data.frame(
                    LeukemiaType =substr(colnames(mat),1,3))
rownames(annotation_col)=colnames(mat)


pheatmap(mat,show_rownames=FALSE,show_colnames=FALSE,
         annotation_col=annotation_col,
         scale = "none",
         clustering_method="ward.D",
         main = "mat without scaling")

pheatmap(scaledMat,show_rownames=FALSE,show_colnames=FALSE,
         annotation_col=annotation_col,
         scale = "none",
         clustering_method="ward.D",
        main = "Scaled mat")

 pheatmap(scaledLogMat,show_rownames=FALSE,show_colnames=FALSE,
         annotation_col=annotation_col,
         scale = "none",
         clustering_method="ward.D",
         main = "Log2 Scaled mat")
 
```

The method argument defines the criteria that directs how the sub-clusters are merged. During clustering, starting with single-member clusters, the clusters are merged based on the distance between them. There are many different ways to define distance between clusters, and based on which definition you use, the hierarchical clustering results change. So the method argument controls that. There are a couple of values this argument can take

```{r message=FALSE, warning=FALSE, include=FALSE}
# Heatmap with no clustering_distance
pheatmap(mat,show_rownames=FALSE,show_colnames=FALSE,
         annotation_col=annotation_col,
         scale = "none",
         clustering_method="ward.D2")
      

# Heatmap with  clustering_distance
pheatmap(mat,show_rownames=FALSE,show_colnames=FALSE,
         annotation_col=annotation_col,
         scale = "none",
         clustering_method="ward.D2",
         clustering_distance_rows ="correlation")

# There is no correct way to choose the clustering method. You should play with it and see what the best result you get.
```

3. For the transformed and untransformed data sets used in the exercise
above, use the silhouette for deciding number of clusters using hierarchical
clustering. [Difficulty: Intermediate/Advanced]
*It seems that the number of clusters is 4, for both transformed and untransformed data sets.*

```{r}

library(cluster)
set.seed(42)

pamclu=cluster::pam(t(mat),k=4)
plot(silhouette(pamclu),main=NULL)
abline(v = pamclu$silinfo$avg.width)



Ks=sapply(2:7,
    function(i) 
      summary(silhouette(pam(t(mat),k=i)))$avg.width)
plot(2:7,Ks,xlab="k",ylab="av. silhouette",type="b",
     pch=19)



Ks=sapply(2:7,
    function(i) 
      summary(silhouette(pam(t(scaledMat),k=i)))$avg.width)
plot(2:7,Ks,xlab="k",ylab="av. silhouette",type="b",
     pch=19)


```

### Dimension reduction

PCA rotates the original data space such that the axes of the new coordinate system point to the directions of highest variance of the data. The axes or new variables are termed principal components (PCs) and are ordered by variance: The first component, PC 1, represents the direction of the highest variance of the data. The direction of the second component, PC 2, represents the highest of the remaining variance orthogonal to the first component. This can be naturally extended to obtain the required number of components, which together span a component space covering the desired amount of variance. In our toy example with only two genes, the principal components are drawn over the original scatter plot and in the next plot we show the new coordinate system based on the principal components. We will calculate the PCA with the princomp() function; this function returns the new coordinates as well. These new coordinates are simply a projection of data over the new coordinates. 

```{r include=FALSE}
par(mfrow=c(1,2))

# create the subset of the data with two genes only
# notice that we transpose the matrix so samples are 
# on the columns
sub.mat=t(mat[rownames(mat) %in% c("ENSG00000100504","ENSG00000105383"),])

# ploting our genes of interest as scatter plots
plot(scale(mat[rownames(mat)=="ENSG00000100504",]),
     scale(mat[rownames(mat)=="ENSG00000105383",]),
     pch=19,
     ylab="CD33 (ENSG00000105383)",
     xlab="PYGL (ENSG00000100504)",
     col=as.factor(annotation_col$LeukemiaType),
     xlim=c(-2,2),ylim=c(-2,2))

# create the legend for the Leukemia types
legend("bottomright",
       legend=unique(annotation_col$LeukemiaType),
       fill =palette("default"),
       border=NA,box.col=NA)

# calculate the PCA only for our genes and all the samples
pr=princomp(scale(sub.mat))


# plot the direction of eigenvectors
# pr$loadings returned by princomp has the eigenvectors
arrows(x0=0, y0=0, x1 = pr$loadings[1,1], 
         y1 = pr$loadings[2,1],col="pink",lwd=3)
arrows(x0=0, y0=0, x1 = pr$loadings[1,2], 
         y1 = pr$loadings[2,2],col="gray",lwd=3)


# plot the samples in the new coordinate system
plot(-pr$scores,pch=19,
     col=as.factor(annotation_col$LeukemiaType),
     ylim=c(-2,2),xlim=c(-4,4))

# plot the new coordinate basis vectors
arrows(x0=0, y0=0, x1 =-2, 
         y1 = 0,col="pink",lwd=3)
arrows(x0=0, y0=0, x1 = 0, 
         y1 = -1,col="gray",lwd=3)

# The arrows represent eigenvectors showing the direction of greatest variation.
```

1. Do PCA on the expression matrix using the princomp() function and then use the screeplot() function to visualize the explained variation by eigenvectors. How many top components explain 95% of the variation? [Difficulty:Beginner]


```{r}
pr=prcomp(t(as.data.frame(scaledMat)))
screeplot(pr, type = "barplot")


s <- summary(pr)

PoV <- s$importance[2,]

sum <- 0

for (i in c(1:length(PoV))) {
        sum = sum + PoV[i]
        if (sum > 0.95) {
                print(paste("95% of the variation is explained by the ",i, " top principal components.", sep = ""))
                break
        }
}

```

```{r message=FALSE, warning=FALSE, include=FALSE}
#PCA
library(stats)
library(ggplot2) 
# install.packages("ggfortify") ggfortify is needed to let ggplot2 know about PCA data structure.
library(ggfortify)

```

```{r}

#compute PCA
pcaResults <- prcomp(t(as.data.frame(scaledMat)))
autoplot(pcaResults, data = annotation_col, colour = 'LeukemiaType')
```

2. In this exercise we use the Rtsne() function on the leukemia expression
data set. Try to increase and decrease perplexity t-sne, and describe the
observed changes in 2D plots. [Difficulty: Beginner]

*By changing the perplexity of the t-sne plot, it seems that using lower values shows a plot with less observable clusters, and as we go up in the perplexity - the samples cluster together (perp = 13), and than start to spread again.*

```{r}
library("Rtsne")
set.seed(42) # Set a seed if you want reproducible results

for (i in seq(1,18, 2)) {
        tsne_out <- Rtsne(t(mat),perplexity = i) # Run TSNE
        #image(t(as.matrix(dist(tsne_out$Y))))
        # Show the objects in the 2D tsne representation
        plot(tsne_out$Y,col=as.factor(annotation_col$LeukemiaType),
             pch=19, main = paste("perplexity =", i))
        # create the legend for the Leukemia types
        legend("bottomleft",
               legend=unique(annotation_col$LeukemiaType),
               fill =palette("default"),
               border=NA,box.col=NA)  
        
}





```







